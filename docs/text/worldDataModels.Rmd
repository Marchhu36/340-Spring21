---
title: "World, Data, and Models"
author: "Karl Rohe"
date: "1/20/2020"
output: 
  html_document:
    number_sections: true
---

These notes weave together a basic understanding for doing science with data. 

**There is a trichotomy between world, data, and models.**

**Science lives in the world. Estimators live with data. Models live in your head.**

**Data let us see the world. Estimators let us see our data. Models let us see our estimators.**

In the fabric of these notes, we will make sense of statistical inference as a know-how that synthesizes your understanding of your world,  data, and model. 

[Data science](DataScience.pdf).

There are five types of statistical practice that we will touch on. We will call them 

1) Experiments    
2) Sampling  
3)  Exploration  
4) Prediction  
5) Observational data analysis

**Experiments**

Sometimes, correlation does imply causation!  This requires that the "treatment" is somehow randomly allocated.  The best example is in a randomized and controlled experiment.

**Example experiment:**  Thirty milk-producing cows are randomly split into two groups of fifteen (treatment vs control).  The treatment group is given a multivitamin in their water.  The treatment group is not.  Over the course of a year, the average amount of milk they produce each day is given below (in pounds).  We want to know if the multivitamin increases milk production.  

```{r}
treatment = c(49,81,73,112,95,88,48,38,39,71,74,60,88,81,79)
control = c(68,63,48,57,70,66,90,44,105,67,59,96,77,79,33)
```

What should we do?  

What might be a different experiment?

**Example:** ball counting video. Randomize the treatment.

**Sampling   **   

Presidential election polls often have +/- 3% "confidence interval".  What is that all about? 

**Example sampling:**  There are roughly 250 million eligible voters in the United States.  We want to estimate what proportion of them expect to vote in the 2020 presidential election.  How might we estimate that? Be more specific than "sampling".  *How* would you sample them?  What might be some difficulties of that technique?  


**Exploration **

What if your data looked like this, what would you do?  

```{r echo= FALSE}
x= rbind(cbind(rnorm(20, 10,2), rnorm(20, 10,2)),cbind(rnorm(20, -10,2), rnorm(20, -10,2)))
par(bty=  "n")
plot(x, xlab = "", ylab=""); lines(c(-100,1000), c(0,0), col = "grey"); lines(c(0,0),c(-100,1000), col = "grey")

```

In *exploration*, we want to group things into clusters or decompose things into separate pieces... but we don't say what those clusters/pieces are.  Instead, we find it in the data.  

**Example exploration:** My research studies how the news media directs our attention. We focus on Twitter.  Given that the news media is highly segmented ("media bubbles"), we grouped leading journalists and media Twitter accounts into 11 different groups.  We did not predetermine what these groups should be!  Instead, we used the data to find "clusters".  In particular, the data we used is who-follows-who on Twitter.  


**Prediction  **

[Chapter 1 in ISLR](http://pages.stat.wisc.edu/~karlrohe/ht/01-introduction.pdf)

See handwritten digits.  

**Observational data analysis**

To be discussed later. 


# Random Variables 

Random variables are a way of expressing random numbers with mathematical notation.   [Here are the lecture notes.](figures/randomVariables.jpg)  

[homework1](homework/01-GenerateRandomVariables.html).

# Monte Carlo Simulation.

Suppose you have a complicated random variable or random process $X$ and you want to know how often $X$ has a certain property $A$.  For example, $X$ could be a number and $A$ could be the property that $X>5$ or $X$ could be a random social network and $A$ could be the property two particular people are friends in that social network.  We write $X \in A$ if $X$ has the property.  We want to know $P(X \in A)$.  As we will see in the next chapters, these are the sorts of probabilities that needed to test hypothesis and create confidence intervals. If you have ever used a Z-table before, it gives you such probabilities for one type of random variable $X$ and one type of set $A$. 

[Monte Carlo simulation](https://en.wikipedia.org/wiki/Monte_Carlo_method) is a way to use a computer to approximate this probability.  The idea is simple.  Simulate the random variable $X$ with your computer.  Then, check if $X$ has that property.  If you can do this 10,000 times, then the proportion of those 10,000 times that $X$ has property $A$ is an estimate of $P(X \in A)$.  Monte Carlo is a key idea for this course.  We will use it again and again and again.  

**[Monte Carlo Examples](MonteCarloExamples.html)**



# Testing; how do you know that you are not fooling yourself?

Randomness creates all sorts of artifacts.  Sometimes, those artifacts look like "signal," leading us to make inferences that are false.  Hypothesis testing asks, "might we have observed this thing simply due to chance?"

If you have learned about hypothesis testing before, buckle up!  We are going to use a more general formulation in this course, using Monte Carlo simulation.  If you have not heard of hypothesis testing, that's ok too!  

[The logic of statistical testing via Monte Carlo Simulation](LogicOfStatisticalTesting.html)

[homework2](homework/02-TestAndEstimate.html).  Note that you can [change the web address](homework/02-TestAndEstimate.Rmd) to get the .Rmd code.  


#  Estimation

In this section, we talk about creating confidence intervals around statistical point estimates.  These confidence intervals are constructed so that they include the point estimate on (e.g.) 95% of experiments.  If you have learned about confidence intervals before, buckle up!  We are going to have a more general approach that uses Monte Carlo simulation. 

[The logic of statistical estimation via Monte Carlo simulation](LogicOfStatisticalEstimation.html)

[Homework 3](homework/03-Estimation.html).

# Variance and the Central Limit Theorem (CLT).

The CLT says that an average of lots of random variables "looks like" a Normal random variable.  [Here are the notes.](VarianceAndTheCentralLimitTheorem.html)


# Prediction    

In a prediction problem, you are given data pairs $(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)$ and you want to use $X_i$ to predict $Y_i$.  We typically imagine $X_i$ as containing several values (i.e. it is a "vector").  

There are two types of prediction problems, continuous $Y_i$ and discrete $Y_i$.  For example, you might want to predict tomorrow's the price for asset $i$ using data that is available today. So, develop an historical training set, where you have information on asset $i$ from one day contained in $X_i$ and that asset's price for the next day contained in $Y_i$.  Here, stock price is continuous.  

Alternatively, you might only be interested in knowing if you should buy the stock, sell the stock, or hold the stock.  So, you develop an historical training set where $X_i$ contains the information that is available on one day. Then, you develop "labels" $Y_i$ using data from the next day that say whether you should have bought, sold, or held onto the asset.  Here, the label (buy, sell, hold) is discrete.  

We will often call continuous outcomes "regression" and discrete outcomes "classification".

Alternatively, perhaps we want to make predictions about the 2020 election.  You could try to predict who is going to win (classification) or the number of delegates/votes that the Republicans recieve (regression).  

In the cases above, there are two natural versions of the same problem (one is regression and one is classification).  However, many classification problems do not have an analogous regression problem.  For example, in the handwritten digit example in [Chapter 1 of ISLR](http://pages.stat.wisc.edu/~karlrohe/ht/01-introduction.pdf), $X_i$ is an image of a handwritten digit and $Y_i$ is a label that says whether the digit is 0, 1, 2, 3, 4,... , or 9.  

We are going to imagine two broad approaches to regression and classification.  

1)  **Model-based approaches** parameterize the distribution of $Y_i$ given $X_i$.  That is, we imagine $Y_i$ being a random variable that follows some distribution and that distribution is somehow parameterized by the variables in $X_i$. 
2)  **Black-box approaches** are defined algorithmically. 

[Chapter 2 in ISLR](http://pages.stat.wisc.edu/~karlrohe/ht/02-statistical_learning.pdf) provides a broad overview of prediction. In the previous weeks of this course, Monte Carlo provided the basic computational tool; we were always working to get the problem stated as something that we could solve with Monte Carlo.  Now, the basic computational tool is numerical optimization. We will not write code to do optimization.  Instead, we will see optimization problems multiple times; it is often used to define our various techniques. 

Note that you can download the textbook for ISLR and get all of the R labs at [the book's website](http://faculty.marshall.usc.edu/gareth-james/ISL/). 

Homework 4:  ISLR (p52) 2.4.1, 2.4.2, 2.4.10.